{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def Models_NO(models, graph):\n",
    "    \n",
    "    # input : model\n",
    "    model = models\n",
    "    #######################################  model fitting \n",
    "    # Data set \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 101)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_total = model.predict(X)\n",
    "    \n",
    "    # graph \n",
    "    if graph:\n",
    "        # pd.crosstab(index, columns) : 교차 Table 만들기\n",
    "        train_matrix = pd.crosstab(y_train, model.predict(X_train), rownames=['Actual'], colnames=['Predicted'])    \n",
    "        test_matrix = pd.crosstab(y_test, model.predict(X_test), rownames=['Actual'], colnames=['Predicted'])\n",
    "        matrix = pd.crosstab(y, model.predict(X), rownames=['Actual'], colnames=['Predicted'])\n",
    "    \n",
    "        # graph - Train, Test, All 3개\n",
    "        f,(ax1,ax2,ax3) = plt.subplots(1,3,sharey=True, figsize=(15, 2))\n",
    "        \n",
    "        # Data Value\n",
    "        g1 = sns.heatmap(train_matrix, annot=True, fmt=\".1f\", cbar=False,annot_kws={\"size\": 18},ax=ax1)\n",
    "        g1.set_title(\"{}/train set\".format(model),fontsize=6)\n",
    "        g1.set_ylabel('Total Churn = {}'.format(1- y_train.sum()), fontsize=14, rotation=90)\n",
    "        g1.set_xlabel('Accuracy for TrainSet: {}'.format(accuracy_score(model.predict(X_train), y_train)))\n",
    "        g1.set_xticklabels(['Churn','Not Churn'],fontsize=6)\n",
    "\n",
    "        g2 = sns.heatmap(test_matrix, annot=True, fmt=\".1f\",cbar=False,annot_kws={\"size\": 18},ax=ax2)\n",
    "        g2.set_title(\"{}/test set\".format(model),fontsize=6)\n",
    "        g2.set_ylabel('Total Churn = {}'.format(1- y_test.sum()), fontsize=14, rotation=90)\n",
    "        g2.set_xlabel('Accuracy for TestSet: {}'.format(accuracy_score(y_pred, y_test)))\n",
    "        g2.set_xticklabels(['Churn','Not Churn'],fontsize=6)\n",
    "\n",
    "        g3 = sns.heatmap(matrix, annot=True, fmt=\".1f\",cbar=False,annot_kws={\"size\": 18},ax=ax3)\n",
    "        g3.set_title(\"{}/total set\".format(model),fontsize=6)\n",
    "        g3.set_ylabel('Total Churn = {}'.format(1- y.sum()), fontsize=14, rotation=90)\n",
    "        g3.set_xlabel('Accuracy for TotalSet: {}'.format(accuracy_score(y_total, y)))\n",
    "        g3.set_xticklabels(['Churn','Not Churn'],fontsize=6)\n",
    "    \n",
    "        plt.show()\n",
    "        print (\"\")\n",
    "        print (\"Classification Report: \")\n",
    "        print (classification_report(y, y_total))\n",
    "        \n",
    "    else:\n",
    "        print(\"\\t\\tError Table\")\n",
    "        print('Mean Absolute Error      : ', metrics.mean_absolute_error(y_test, (y_pred)))\n",
    "        print('Mean Squared  Error      : ', metrics.mean_squared_error(y_test, (y_pred) ))\n",
    "        print('Root Mean Squared  Error : ', np.sqrt(metrics.mean_squared_error(y_test, (y_pred) )))\n",
    "        print('Accuracy on Traing set   : ', model.score(X_train,y_train))\n",
    "        print('Accuracy on Testing set  : ', model.score(X_test,y_test))\n",
    "        print('AUC score                :', roc_auc_score(y, y_total)*100,'%')        \n",
    "    return y_total, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![classification_report_ex](./classification_report_ex.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Searching optimal parameters for precision_weighted\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ExtraTreesClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-1688dc7b3932>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;31m#classifier.fit(X_train, y_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mExtraTreesClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameter_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ExtraTreesClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 여기에선 n_estimators 및 max_depth 매개변수에 대한 최적값 찾는다.\n",
    "### Parameter grid\n",
    "parameter_grid = [ {'n_estimators': [100], 'max_depth': [2, 4, 7, 12, 16]},\n",
    "                   {'max_depth': [4], 'n_estimators': [25, 50, 100, 250]}\n",
    "                 ]\n",
    "\n",
    "# 분류기에서 매개변수의 최적 조합을 찾기 위해 사용할 성능 지표\n",
    "metrics = ['precision_weighted', 'recall_weighted']\n",
    "\n",
    "# 각 성능 지표 항목별로 그리드 검색을 통해 최적의 매개변수를 찾고 이를 이용해 분류기 학습\n",
    "for metric in metrics:\n",
    "    print(\"\\n##### Searching optimal parameters for\", metric)\n",
    "\n",
    "    #classifier = grid_search.GridSearchCV(\n",
    "            #ExtraTreesClassifier(random_state=0), parameter_grid, cv=5, scoring=metric)\n",
    "            #classifier.fit(X_train, y_train)\n",
    "    \n",
    "    grid = GridSearchCV(ExtraTreesClassifier(random_state=0), parameter_grid, scoring=metric)\n",
    "    grid.fit(X, y)\n",
    "\n",
    "    # 각 매개변수 조합별로 점수 출력\n",
    "    print(\"\\nGrid scores for the parameter grid:\")\n",
    "    #for params, avg_score, _ in grid.best_score_:\n",
    "        #print(params, '-->', round(avg_score, 3))\n",
    "        \n",
    "    print(grid.best_score_)\n",
    "\n",
    "    print(\"\\nBest parameters:\", grid.best_estimator_)\n",
    "\n",
    "    # 성능 리포트 출력\n",
    "    y_pred = grid.predict(X_test)\n",
    "    print(\"\\nPerformance report:\\n\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![classification_report_ex2](./classification_report_ex2.JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
